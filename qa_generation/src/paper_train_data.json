[
    {
        "id":"abs-2305.14331v2",
        "title":"What Else Do I Need to Know? The Effect of Background Information on\n  Users' Reliance on QA Systems",
        "first_author":"'Navita Goyal'",
        "summary":"NLP systems have shown impressive performance at answering questions by\nretrieving relevant context. However, with the increasingly large models, it is\nimpossible and often undesirable to constrain models' knowledge or reasoning to\nonly the retrieved context. This leads to a mismatch between the information\nthat the models access to derive the answer and the information that is\navailable to the user to assess the model predicted answer. In this work, we\nstudy how users interact with QA systems in the absence of sufficient\ninformation to assess their predictions. Further, we ask whether adding the\nrequisite background helps mitigate users' over-reliance on predictions. Our\nstudy reveals that users rely on model predictions even in the absence of\nsufficient information needed to assess the model's correctness. Providing the\nrelevant background, however, helps users better catch model errors, reducing\nover-reliance on incorrect predictions. On the flip side, background\ninformation also increases users' confidence in their accurate as well as\ninaccurate judgments. Our work highlights that supporting users' verification\nof QA predictions is an important, yet challenging, problem."
    },
    {
        "id":"abs-1510.00331v3",
        "title":"Multimodal Hierarchical Dirichlet Process-based Active Perception",
        "first_author":"'Tadahiro Taniguchi'",
        "summary":"In this paper, we propose an active perception method for recognizing object\ncategories based on the multimodal hierarchical Dirichlet process (MHDP). The\nMHDP enables a robot to form object categories using multimodal information,\ne.g., visual, auditory, and haptic information, which can be observed by\nperforming actions on an object. However, performing many actions on a target\nobject requires a long time. In a real-time scenario, i.e., when the time is\nlimited, the robot has to determine the set of actions that is most effective\nfor recognizing a target object. We propose an MHDP-based active perception\nmethod that uses the information gain (IG) maximization criterion and lazy\ngreedy algorithm. We show that the IG maximization criterion is optimal in the\nsense that the criterion is equivalent to a minimization of the expected\nKullback--Leibler divergence between a final recognition state and the\nrecognition state after the next set of actions. However, a straightforward\ncalculation of IG is practically impossible. Therefore, we derive an efficient\nMonte Carlo approximation method for IG by making use of a property of the\nMHDP. We also show that the IG has submodular and non-decreasing properties as\na set function because of the structure of the graphical model of the MHDP.\nTherefore, the IG maximization problem is reduced to a submodular maximization\nproblem. This means that greedy and lazy greedy algorithms are effective and\nhave a theoretical justification for their performance. We conducted an\nexperiment using an upper-torso humanoid robot and a second one using synthetic\ndata. The experimental results show that the method enables the robot to select\na set of actions that allow it to recognize target objects quickly and\naccurately. The results support our theoretical outcomes."
    },
    {
        "id":"abs-1907.09140v2",
        "title":"Multi-scale Cell Instance Segmentation with Keypoint Graph based\n  Bounding Boxes",
        "first_author":"'Jingru Yi'",
        "summary":"Most existing methods handle cell instance segmentation problems directly\nwithout relying on additional detection boxes. These methods generally fails to\nseparate touching cells due to the lack of global understanding of the objects.\nIn contrast, box-based instance segmentation solves this problem by combining\nobject detection with segmentation. However, existing methods typically utilize\nanchor box-based detectors, which would lead to inferior instance segmentation\nperformance due to the class imbalance issue. In this paper, we propose a new\nbox-based cell instance segmentation method. In particular, we first detect the\nfive pre-defined points of a cell via keypoints detection. Then we group these\npoints according to a keypoint graph and subsequently extract the bounding box\nfor each cell. Finally, cell segmentation is performed on feature maps within\nthe bounding boxes. We validate our method on two cell datasets with distinct\nobject shapes, and empirically demonstrate the superiority of our method\ncompared to other instance segmentation techniques. Code is available at:\nhttps:\/\/github.com\/yijingru\/KG_Instance_Segmentation."
    },
    {
        "id":"abs-2010.12880v2",
        "title":"Persian Handwritten Digit, Character and Word Recognition Using Deep\n  Learning",
        "first_author":"'Mehdi Bonyani'",
        "summary":"Digit, letter and word recognition for a particular script has various\napplications in todays commercial contexts. Nevertheless, only a limited number\nof relevant studies have dealt with Persian scripts. In this paper, deep neural\nnetworks are utilized through various DensNet architectures, as well as the\nXception, are adopted, modified and further boosted through data augmentation\nand test time augmentation, in order to come up with an optical character\nrecognition accounting for the particularities of the Persian language and the\ncorresponding handwritings. Taking advantage of dividing the databases to\ntraining, validation and test sets, as well as k-fold cross validation, the\ncomparison of the proposed method with various state-of-the-art alternatives is\nperformed on the basis of the HODA and Sadri databases, which offer the most\ncomprehensive collection of samples in terms of the various handwriting styles\npossessed by different human beings, as well as different forms each letter may\ntake, which depend on its position within a word. On the HODA database, we\nachieve recognition rates of 99.72% and 89.99% for digits and characters, being\n99.72%, 98.32% and 98.82% for digits, characters and words from the Sadri\ndatabase, respectively."
    },
    {
        "id":"abs-2102.11174v3",
        "title":"Linear Transformers Are Secretly Fast Weight Programmers",
        "first_author":"'Imanol Schlag'",
        "summary":"We show the formal equivalence of linearised self-attention mechanisms and\nfast weight controllers from the early '90s, where a ``slow\" neural net learns\nby gradient descent to program the ``fast weights\" of another net through\nsequences of elementary programming instructions which are additive outer\nproducts of self-invented activation patterns (today called keys and values).\nSuch Fast Weight Programmers (FWPs) learn to manipulate the contents of a\nfinite memory and dynamically interact with it. We infer a memory capacity\nlimitation of recent linearised softmax attention variants, and replace the\npurely additive outer products by a delta rule-like programming instruction,\nsuch that the FWP can more easily learn to correct the current mapping from\nkeys to values. The FWP also learns to compute dynamically changing learning\nrates. We also propose a new kernel function to linearise attention which\nbalances simplicity and effectiveness. We conduct experiments on synthetic\nretrieval problems as well as standard machine translation and language\nmodelling tasks which demonstrate the benefits of our methods."
    },
    {
        "id":"abs-2010.16326v1",
        "title":"All of the Fairness for Edge Prediction with Optimal Transport",
        "first_author":"'Charlotte Laclau'",
        "summary":"Machine learning and data mining algorithms have been increasingly used\nrecently to support decision-making systems in many areas of high societal\nimportance such as healthcare, education, or security. While being very\nefficient in their predictive abilities, the deployed algorithms sometimes tend\nto learn an inductive model with a discriminative bias due to the presence of\nthis latter in the learning sample. This problem gave rise to a new field of\nalgorithmic fairness where the goal is to correct the discriminative bias\nintroduced by a certain attribute in order to decorrelate it from the model's\noutput. In this paper, we study the problem of fairness for the task of edge\nprediction in graphs, a largely underinvestigated scenario compared to a more\npopular setting of fair classification. To this end, we formulate the problem\nof fair edge prediction, analyze it theoretically, and propose an\nembedding-agnostic repairing procedure for the adjacency matrix of an arbitrary\ngraph with a trade-off between the group and individual fairness. We\nexperimentally show the versatility of our approach and its capacity to provide\nexplicit control over different notions of fairness and prediction accuracy."
    },
    {
        "id":"abs-1708.05522v1",
        "title":"Exploring Directional Path-Consistency for Solving Constraint Networks",
        "first_author":"'Shufeng Kong'",
        "summary":"Among the local consistency techniques used for solving constraint networks,\npath-consistency (PC) has received a great deal of attention. However,\nenforcing PC is computationally expensive and sometimes even unnecessary.\nDirectional path-consistency (DPC) is a weaker notion of PC that considers a\ngiven variable ordering and can thus be enforced more efficiently than PC. This\npaper shows that DPC (the DPC enforcing algorithm of Dechter and Pearl) decides\nthe constraint satisfaction problem (CSP) of a constraint language if it is\ncomplete and has the variable elimination property (VEP). However, we also show\nthat no complete VEP constraint language can have a domain with more than 2\nvalues. We then present a simple variant of the DPC algorithm, called DPC*, and\nshow that the CSP of a constraint language can be decided by DPC* if it is\nclosed under a majority operation. In fact, DPC* is sufficient for guaranteeing\nbacktrack-free search for such constraint networks. Examples of majority-closed\nconstraint classes include the classes of connected row-convex (CRC)\nconstraints and tree-preserving constraints, which have found applications in\nvarious domains, such as scene labeling, temporal reasoning, geometric\nreasoning, and logical filtering. Our experimental evaluations show that DPC*\nsignificantly outperforms the state-of-the-art algorithms for solving\nmajority-closed constraints."
    },
    {
        "id":"abs-1604.01841v1",
        "title":"A Classification Leveraged Object Detector",
        "first_author":"'Miao Sun'",
        "summary":"Currently, the state-of-the-art image classification algorithms outperform\nthe best available object detector by a big margin in terms of average\nprecision. We, therefore, propose a simple yet principled approach that allows\nus to leverage object detection through image classification on supporting\nregions specified by a preliminary object detector. Using a simple bag-of-\nwords model based image classification algorithm, we leveraged the performance\nof the deformable model objector from 35.9% to 39.5% in average precision over\n20 categories on standard PASCAL VOC 2007 detection dataset."
    },
    {
        "id":"abs-2305.19455v1",
        "title":"Implementation of a framework for deploying AI inference engines in\n  FPGAs",
        "first_author":"'Ryan Herbst'",
        "summary":"The LCLS2 Free Electron Laser FEL will generate xray pulses to beamline\nexperiments at up to 1Mhz These experimentals will require new ultrahigh rate\nUHR detectors that can operate at rates above 100 kHz and generate data\nthroughputs upwards of 1 TBs a data velocity which requires prohibitively large\ninvestments in storage infrastructure Machine Learning has demonstrated the\npotential to digest large datasets to extract relevant insights however current\nimplementations show latencies that are too high for realtime data reduction\nobjectives SLAC has endeavored on the creation of a software framework which\ntranslates MLs structures for deployment on Field Programmable Gate Arrays\nFPGAs deployed at the Edge of the data chain close to the instrumentation This\nframework leverages Xilinxs HLS framework presenting an API modeled after the\nopen source Keras interface to the TensorFlow library This SLAC Neural Network\nLibrary SNL framework is designed with a streaming data approach optimizing the\ndata flow between layers while minimizing the buffer data buffering\nrequirements The goal is to ensure the highest possible framerate while keeping\nthe maximum latency constrained to the needs of the experiment Our framework is\ndesigned to ensure the RTL implementation of the network layers supporting full\nredeployment of weights and biases without requiring resynthesis after training\nThe ability to reduce the precision of the implemented networks through\nquantization is necessary to optimize the use of both DSP and memory resources\nin the FPGA We currently have a preliminary version of the toolset and are\nexperimenting with both general purpose example networks and networks being\ndesigned for specific LCLS2 experiments."
    },
    {
        "id":"abs-1711.00388v1",
        "title":"Active Tolerant Testing",
        "first_author":"'Avrim Blum'",
        "summary":"In this work, we give the first algorithms for tolerant testing of nontrivial\nclasses in the active model: estimating the distance of a target function to a\nhypothesis class C with respect to some arbitrary distribution D, using only a\nsmall number of label queries to a polynomial-sized pool of unlabeled examples\ndrawn from D. Specifically, we show that for the class D of unions of d\nintervals on the line, we can estimate the error rate of the best hypothesis in\nthe class to an additive error epsilon from only $O(\\frac{1}{\\epsilon^6}\\log\n\\frac{1}{\\epsilon})$ label queries to an unlabeled pool of size\n$O(\\frac{d}{\\epsilon^2}\\log \\frac{1}{\\epsilon})$. The key point here is the\nnumber of labels needed is independent of the VC-dimension of the class. This\nextends the work of Balcan et al. [2012] who solved the non-tolerant testing\nproblem for this class (distinguishing the zero-error case from the case that\nthe best hypothesis in the class has error greater than epsilon).\n  We also consider the related problem of estimating the performance of a given\nlearning algorithm A in this setting. That is, given a large pool of unlabeled\nexamples drawn from distribution D, can we, from only a few label queries,\nestimate how well A would perform if the entire dataset were labeled? We focus\non k-Nearest Neighbor style algorithms, and also show how our results can be\napplied to the problem of hyperparameter tuning (selecting the best value of k\nfor the given learning problem)."
    },
    {
        "id":"abs-1301.7384v1",
        "title":"An Anytime Algorithm for Decision Making under Uncertainty",
        "first_author":"'Michael C. Horsch'",
        "summary":"We present an anytime algorithm which computes policies for decision problems\nrepresented as multi-stage influence diagrams. Our algorithm constructs\npolicies incrementally, starting from a policy which makes no use of the\navailable information. The incremental process constructs policies which\nincludes more of the information available to the decision maker at each step.\nWhile the process converges to the optimal policy, our approach is designed for\nsituations in which computing the optimal policy is infeasible. We provide\nexamples of the process on several large decision problems, showing that, for\nthese examples, the process constructs valuable (but sub-optimal) policies\nbefore the optimal policy would be available by traditional methods."
    },
    {
        "id":"abs-2301.12855v1",
        "title":"How Far Can It Go?: On Intrinsic Gender Bias Mitigation for Text\n  Classification",
        "first_author":"'Ewoenam Tokpo'",
        "summary":"To mitigate gender bias in contextualized language models, different\nintrinsic mitigation strategies have been proposed, alongside many bias\nmetrics. Considering that the end use of these language models is for\ndownstream tasks like text classification, it is important to understand how\nthese intrinsic bias mitigation strategies actually translate to fairness in\ndownstream tasks and the extent of this. In this work, we design a probe to\ninvestigate the effects that some of the major intrinsic gender bias mitigation\nstrategies have on downstream text classification tasks. We discover that\ninstead of resolving gender bias, intrinsic mitigation techniques and metrics\nare able to hide it in such a way that significant gender information is\nretained in the embeddings. Furthermore, we show that each mitigation technique\nis able to hide the bias from some of the intrinsic bias measures but not all,\nand each intrinsic bias measure can be fooled by some mitigation techniques,\nbut not all. We confirm experimentally, that none of the intrinsic mitigation\ntechniques used without any other fairness intervention is able to consistently\nimpact extrinsic bias. We recommend that intrinsic bias mitigation techniques\nshould be combined with other fairness interventions for downstream tasks."
    },
    {
        "id":"abs-2005.05179v4",
        "title":"Reference Pose Generation for Long-term Visual Localization via Learned\n  Features and View Synthesis",
        "first_author":"'Zichao Zhang'",
        "summary":"Visual Localization is one of the key enabling technologies for autonomous\ndriving and augmented reality. High quality datasets with accurate 6\nDegree-of-Freedom (DoF) reference poses are the foundation for benchmarking and\nimproving existing methods. Traditionally, reference poses have been obtained\nvia Structure-from-Motion (SfM). However, SfM itself relies on local features\nwhich are prone to fail when images were taken under different conditions,\ne.g., day\/ night changes. At the same time, manually annotating feature\ncorrespondences is not scalable and potentially inaccurate. In this work, we\npropose a semi-automated approach to generate reference poses based on feature\nmatching between renderings of a 3D model and real images via learned features.\nGiven an initial pose estimate, our approach iteratively refines the pose based\non feature matches against a rendering of the model from the current pose\nestimate. We significantly improve the nighttime reference poses of the popular\nAachen Day-Night dataset, showing that state-of-the-art visual localization\nmethods perform better (up to $47\\%$) than predicted by the original reference\nposes. We extend the dataset with new nighttime test images, provide\nuncertainty estimates for our new reference poses, and introduce a new\nevaluation criterion. We will make our reference poses and our framework\npublicly available upon publication."
    },
    {
        "id":"abs-1910.12132v1",
        "title":"Bayesian Graph Convolutional Neural Networks Using Non-Parametric Graph\n  Learning",
        "first_author":"'Soumyasundar Pal'",
        "summary":"Graph convolutional neural networks (GCNN) have been successfully applied to\nmany different graph based learning tasks including node and graph\nclassification, matrix completion, and learning of node embeddings. Despite\ntheir impressive performance, the techniques have a limited capability to\nincorporate the uncertainty in the underlined graph structure. In order to\naddress this issue, a Bayesian GCNN (BGCN) framework was recently proposed. In\nthis framework, the observed graph is considered to be a random realization\nfrom a parametric random graph model and the joint Bayesian inference of the\ngraph and GCNN weights is performed. In this paper, we propose a non-parametric\ngenerative model for graphs and incorporate it within the BGCN framework. In\naddition to the observed graph, our approach effectively uses the node features\nand training labels in the posterior inference of graphs and attains superior\nor comparable performance in benchmark node classification tasks."
    },
    {
        "id":"abs-2001.11216v2",
        "title":"How Does BN Increase Collapsed Neural Network Filters?",
        "first_author":"'Sheng Zhou'",
        "summary":"Improving sparsity of deep neural networks (DNNs) is essential for network\ncompression and has drawn much attention. In this work, we disclose a harmful\nsparsifying process called filter collapse, which is common in DNNs with batch\nnormalization (BN) and rectified linear activation functions (e.g. ReLU, Leaky\nReLU). It occurs even without explicit sparsity-inducing regularizations such\nas $L_1$. This phenomenon is caused by the normalization effect of BN, which\ninduces a non-trainable region in the parameter space and reduces the network\ncapacity as a result. This phenomenon becomes more prominent when the network\nis trained with large learning rates (LR) or adaptive LR schedulers, and when\nthe network is finetuned. We analytically prove that the parameters of BN tend\nto become sparser during SGD updates with high gradient noise and that the\nsparsifying probability is proportional to the square of learning rate and\ninversely proportional to the square of the scale parameter of BN. To prevent\nthe undesirable collapsed filters, we propose a simple yet effective approach\nnamed post-shifted BN (psBN), which has the same representation ability as BN\nwhile being able to automatically make BN parameters trainable again as they\nsaturate during training. With psBN, we can recover collapsed filters and\nincrease the model performance in various tasks such as classification on\nCIFAR-10 and object detection on MS-COCO2017."
    },
    {
        "id":"abs-2308.06182v1",
        "title":"Noise-Resilient Designs for Optical Neural Networks",
        "first_author":"'Gianluca Kosmella'",
        "summary":"All analog signal processing is fundamentally subject to noise, and this is\nalso the case in modern implementations of Optical Neural Networks (ONNs).\nTherefore, to mitigate noise in ONNs, we propose two designs that are\nconstructed from a given, possibly trained, Neural Network (NN) that one wishes\nto implement. Both designs have the capability that the resulting ONNs gives\noutputs close to the desired NN.\n  To establish the latter, we analyze the designs mathematically. Specifically,\nwe investigate a probabilistic framework for the first design that establishes\nthat the design is correct, i.e., for any feed-forward NN with Lipschitz\ncontinuous activation functions, an ONN can be constructed that produces output\narbitrarily close to the original. ONNs constructed with the first design thus\nalso inherit the universal approximation property of NNs. For the second\ndesign, we restrict the analysis to NNs with linear activation functions and\ncharacterize the ONNs' output distribution using exact formulas.\n  Finally, we report on numerical experiments with LeNet ONNs that give insight\ninto the number of components required in these designs for certain accuracy\ngains. We specifically study the effect of noise as a function of the depth of\nan ONN. The results indicate that in practice, adding just a few components in\nthe manner of the first or the second design can already be expected to\nincrease the accuracy of ONNs considerably."
    },
    {
        "id":"abs-2304.13540v1",
        "title":"Byzantine-Resilient Learning Beyond Gradients: Distributing Evolutionary\n  Search",
        "first_author":"'Andrei Kucharavy'",
        "summary":"Modern machine learning (ML) models are capable of impressive performances.\nHowever, their prowess is not due only to the improvements in their\narchitecture and training algorithms but also to a drastic increase in\ncomputational power used to train them.\n  Such a drastic increase led to a growing interest in distributed ML, which in\nturn made worker failures and adversarial attacks an increasingly pressing\nconcern. While distributed byzantine resilient algorithms have been proposed in\na differentiable setting, none exist in a gradient-free setting.\n  The goal of this work is to address this shortcoming. For that, we introduce\na more general definition of byzantine-resilience in ML - the\n\\textit{model-consensus}, that extends the definition of the classical\ndistributed consensus. We then leverage this definition to show that a general\nclass of gradient-free ML algorithms - ($1,\\lambda$)-Evolutionary Search - can\nbe combined with classical distributed consensus algorithms to generate\ngradient-free byzantine-resilient distributed learning algorithms. We provide\nproofs and pseudo-code for two specific cases - the Total Order Broadcast and\nproof-of-work leader election."
    },
    {
        "id":"abs-2204.09594v1",
        "title":"Predicting Clinical Intent from Free Text Electronic Health Records",
        "first_author":"'Kawsar Noor'",
        "summary":"After a patient consultation, a clinician determines the steps in the\nmanagement of the patient. A clinician may for example request to see the\npatient again or refer them to a specialist. Whilst most clinicians will record\ntheir intent as \"next steps\" in the patient's clinical notes, in some cases the\nclinician may forget to indicate their intent as an order or request, e.g.\nfailure to place the follow-up order. This consequently results in patients\nbecoming lost-to-follow up and may in some cases lead to adverse consequences.\nIn this paper we train a machine learning model to detect a clinician's intent\nto follow up with a patient from the patient's clinical notes. Annotators\nsystematically identified 22 possible types of clinical intent and annotated\n3000 Bariatric clinical notes. The annotation process revealed a class\nimbalance in the labeled data and we found that there was only sufficient\nlabeled data to train 11 out of the 22 intents. We used the data to train a\nBERT based multilabel classification model and reported the following average\naccuracy metrics for all intents: macro-precision: 0.91, macro-recall: 0.90,\nmacro-f1: 0.90."
    },
    {
        "id":"abs-2406.10880v2",
        "title":"Exploring the Potential of Multimodal LLM with Knowledge-Intensive\n  Multimodal ASR",
        "first_author":"'Minghan Wang'",
        "summary":"Recent advancements in multimodal large language models (MLLMs) have made\nsignificant progress in integrating information across various modalities, yet\nreal-world applications in educational and scientific domains remain\nchallenging. This paper introduces the Multimodal Scientific ASR (MS-ASR) task,\nwhich focuses on transcribing scientific conference videos by leveraging visual\ninformation from slides to enhance the accuracy of technical terminologies.\nRealized that traditional metrics like WER fall short in assessing performance\naccurately, prompting the proposal of severity-aware WER (SWER) that considers\nthe content type and severity of ASR errors. We propose the Scientific Vision\nAugmented ASR (SciVASR) framework as a baseline method, enabling MLLMs to\nimprove transcript quality through post-editing. Evaluations of\nstate-of-the-art MLLMs, including GPT-4o, show a 45% improvement over\nspeech-only baselines, highlighting the importance of multimodal information\nintegration."
    },
    {
        "id":"abs-1609.08267v2",
        "title":"De-noising, Stabilizing and Completing 3D Reconstructions On-the-go\n  using Plane Priors",
        "first_author":"'Maksym Dzitsiuk'",
        "summary":"Creating 3D maps on robots and other mobile devices has become a reality in\nrecent years. Online 3D reconstruction enables many exciting applications in\nrobotics and AR\/VR gaming. However, the reconstructions are noisy and generally\nincomplete. Moreover, during onine reconstruction, the surface changes with\nevery newly integrated depth image which poses a significant challenge for\nphysics engines and path planning algorithms. This paper presents a novel, fast\nand robust method for obtaining and using information about planar surfaces,\nsuch as walls, floors, and ceilings as a stage in 3D reconstruction based on\nSigned Distance Fields. Our algorithm recovers clean and accurate surfaces,\nreduces the movement of individual mesh vertices caused by noise during online\nreconstruction and fills in the occluded and unobserved regions. We implemented\nand evaluated two different strategies to generate plane candidates and two\nstrategies for merging them. Our implementation is optimized to run in\nreal-time on mobile devices such as the Tango tablet. In an extensive set of\nexperiments, we validated that our approach works well in a large number of\nnatural environments despite the presence of significant amount of occlusion,\nclutter and noise, which occur frequently. We further show that plane fitting\nenables in many cases a meaningful semantic segmentation of real-world scenes."
    }
]